{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d7eee9-1351-456c-92e0-cb9574cabdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411159ab-4fc0-4545-8ff0-9a6a6a4c5fa5",
   "metadata": {},
   "source": [
    "testing TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0b6ffc-c53a-4d18-8ec8-95ffea61bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = TextBlob(\"TextBlob has some interesting features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6945837f-18d7-4d36-9d6f-56ec174158d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cmpkey', '_compare', '_create_sentence_objects', '_strkey', 'analyzer', 'classifier', 'classify', 'correct', 'ends_with', 'endswith', 'find', 'format', 'index', 'join', 'json', 'lower', 'ngrams', 'noun_phrases', 'np_counts', 'np_extractor', 'parse', 'parser', 'polarity', 'pos_tagger', 'pos_tags', 'raw', 'raw_sentences', 'replace', 'rfind', 'rindex', 'sentences', 'sentiment', 'sentiment_assessments', 'serialized', 'split', 'starts_with', 'startswith', 'string', 'strip', 'stripped', 'subjectivity', 'tags', 'title', 'to_json', 'tokenize', 'tokenizer', 'tokens', 'upper', 'word_counts', 'words']\n"
     ]
    }
   ],
   "source": [
    "print(dir(analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae9eb3a-25e7-4856-966e-00fcfadfefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/sakshi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /home/sakshi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sakshi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/sakshi/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package conll2000 to /home/sakshi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/sakshi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!python3 -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac7c75a-d6f9-4b11-8357-35cb83d36c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TextBlob', 'NNP'), ('has', 'VBZ'), ('some', 'DT'), ('interesting', 'JJ'), ('features', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(analysis.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d506a01a-6eb4-47ea-bbb0-6c660214c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.5)\n"
     ]
    }
   ],
   "source": [
    "print(analysis.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb665e7-c93a-4b21-85e5-049e76e3acb2",
   "metadata": {},
   "source": [
    "assume positive has only positive and negative has only negative sentences  \n",
    "use TextBlob to analyze sentiment polarity  \n",
    "count correct predictions where polarity > 0.1 for positive and â‰¤ 0.1 for negative  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9f910a-dfa6-431a-bec6-ea137564da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 60.49128070504407% via 5333 samples\n",
      "Negative accuracy = 68.38552409525596% via 5333 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.polarity > 0.1:\n",
    "            pos_correct += 1\n",
    "        pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.polarity <= 0.1:\n",
    "            neg_correct += 1\n",
    "        neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aca360-a272-4e80-9be1-03be55fa9907",
   "metadata": {},
   "source": [
    "filter sentences that have subjectivity greater than 0.5  \n",
    "but this reduces the sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5ad41de-1b4d-47b6-be68-3ec61ecffbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 82.02557898375389% via 2893 samples\n",
      "Negative accuracy = 52.00506542845083% via 2369 samples\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "\n",
    "        if analysis.sentiment.subjectivity > 0.5:\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        analysis = TextBlob(line)\n",
    "        if analysis.sentiment.subjectivity > 0.5:\n",
    "            if analysis.sentiment.polarity <= 0:\n",
    "                neg_correct += 1\n",
    "            neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e4d12-6faa-4782-95f8-a65760a7d766",
   "metadata": {},
   "source": [
    "## testing VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef737216-a4a2-433d-9e9d-0d1524a66de0",
   "metadata": {},
   "source": [
    "gives positive, negative, neutral and compound score\n",
    "compound score is between -1 (most extreme negative) to +1 (most extreme positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe992fa7-d1be-40d2-86b7-436fa70f33c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.509, 'pos': 0.491, 'compound': 0.6996}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(\"VADER Sentiment looks interesting, I have high hopes!\")\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ce8de0d-07ca-4d39-be15-d8b3bd5accff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 70.16688543033939% via 5333 samples\n",
      "Negative accuracy = 57.39733733358335% via 5333 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if vs['compound'] > 0:\n",
    "            pos_correct += 1\n",
    "        pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if vs['compound'] <= 0:\n",
    "            neg_correct += 1\n",
    "        neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976bb27-da38-4c9c-955a-29f1c872d4f6",
   "metadata": {},
   "source": [
    "using a threshold is recommended by the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a6a767f-b0f0-43ea-a882-4dfbf60b6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 87.66037735849056% via 2650 samples\n",
      "Negative accuracy = 49.56140350877193% via 1824 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "with open(\"positive\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "\n",
    "        if vs['compound'] >= threshold or vs['compound'] <= -threshold:\n",
    "            if vs['compound'] > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if vs['compound'] >= threshold or vs['compound'] <= -threshold:\n",
    "            if vs['compound'] <= 0:\n",
    "                neg_correct += 1\n",
    "            neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a54429-867d-47a5-b82d-1cf573f27387",
   "metadata": {},
   "source": [
    "looking for no conflict  \n",
    "so to classify something as positive, the negative score should be less than 0.1  \n",
    "and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cff9ce0-c61d-43e5-ad0b-7b0f74018589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy = 81.01049548450085% via 4097 samples\n",
      "Negative accuracy = 89.27229244960711% via 2927 samples\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0\n",
    "pos_correct = 0\n",
    "\n",
    "with open(\"positive\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if not vs['neg'] > 0.1:\n",
    "            if vs['pos']-vs['neg'] > 0:\n",
    "                pos_correct += 1\n",
    "            pos_count +=1\n",
    "\n",
    "\n",
    "neg_count = 0\n",
    "neg_correct = 0\n",
    "\n",
    "with open(\"negative\",\"r\") as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        vs = analyzer.polarity_scores(line)\n",
    "        if not vs['pos'] > 0.1:\n",
    "            if vs['pos']-vs['neg'] <= 0:\n",
    "                neg_correct += 1\n",
    "            neg_count +=1\n",
    "\n",
    "print(\"Positive accuracy = {}% via {} samples\".format(pos_correct/pos_count*100.0, pos_count))\n",
    "print(\"Negative accuracy = {}% via {} samples\".format(neg_correct/neg_count*100.0, neg_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
